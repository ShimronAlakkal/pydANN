{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pydANN ( python deep Artificial Neural Network )\n",
    "\n",
    "is a free and open source python library to implement the Machine Learning algorithm of neural networks\n",
    "The network can be as simple as a sinle layer perceptron net or a multi-layer deep neural net.\n",
    "THe design and modifications of this library is posted [here](https://www.github.com/ShimronAlakkal)\n",
    "\n",
    "\n",
    "### 1 - Packages\n",
    "\n",
    "These are some of the most important packages that you're going to need in order to use ***```pydANN```***\n",
    "\n",
    "- [numpy](www.numpy.org) (or numeric python) is the main package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a library to plot graphs -- which are optional -- in Python.\n",
    "- [pickle](https://docs.python.org/3/library/pickle.html) is the library pydANN uses to save your trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom tools (functions) that are called inside of the activation layer.\n",
    "To specify the activation function for a layer use `activation_specific = f` with `addHL()`,  where `f` is a list, of length of hidden layers + 1, and each index with a custom function name.\n",
    "If there is a mismatch in the input activation_specifics, the model is going to auto adjust the activation with the last ones from your input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1 / 1 + np.exp(-Z)\n",
    "\n",
    "def leaky_relu(Z):\n",
    "    return np.maximum(0.1*Z)\n",
    "\n",
    "def sigmoid_derivative(Z):\n",
    "    return sigmoid(Z) * ( 1 - sigmoid(Z) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ann:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hidden_Layers = [3,2]\n",
    "        self.total_layers = []\n",
    "        self.learning_rate = 0.001\n",
    "        self.epoch = 0\n",
    "        self.W = {}\n",
    "        self.b = {}\n",
    "        self.Z = {}\n",
    "        self.A = {}\n",
    "        self.activation_functions = []\n",
    "        self.costs = [0]\n",
    "        self.dW = {}\n",
    "        self.db = {}\n",
    "        self.dZ = {}\n",
    "        self.dA = {}\n",
    "        self.lr_change = []\n",
    "        \n",
    "    \n",
    "    \n",
    "    def add_hl(self,hl,activations ):\n",
    "        self.hidden_Layers.clear()\n",
    "        self.hidden_Layers = hl\n",
    "        \n",
    "        # settingf the activations\n",
    "        if len(activations) == len(hl)+1:\n",
    "            self.activation_functions = activations\n",
    "        else:\n",
    "            print('Passed activations should be 1 more than the HL length \\n recall the function to override HL')\n",
    "                \n",
    "        \n",
    "    def dispose_model(self):\n",
    "        self.total_layers.clear()\n",
    "        self.hidden_Layers.clear()\n",
    "        self.costs.clear()\n",
    "        self.lr_change.clear()\n",
    "        self.Z.clear()\n",
    "        self.W.clear()\n",
    "        self.b.clear()\n",
    "        self.db.clear()\n",
    "        self.dW.clear()\n",
    "        self.dZ.clear()\n",
    "        self.dA.clear()\n",
    "            \n",
    "    def register_training_data(self,train_x,train_y):\n",
    "        self.total_layers.clear()\n",
    "        self.total_layers.append(train_x.shape[0])\n",
    "        for i in self.hidden_Layers:\n",
    "            self.total_layers.append(i)\n",
    "       \n",
    "        # network structure\n",
    "        self.total_layers.append(train_y.shape[0])\n",
    "        print(f\"Network structure update :{self.total_layers}\\n feature(s) : {self.total_layers[0]} \\n label(s) : {self.total_layers[-1]} \\n hidden layers : {self.hidden_Layers}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def init_Params(self,verbose = False):\n",
    "        \n",
    "        # creating the weights and biases with seed(1)\n",
    "        np.random.seed(144)\n",
    "        for i in range(1,len(self.total_layers)):\n",
    "            \n",
    "            self.W['W'+str(i)] = np.random.randn(self.total_layers[i],self.total_layers[i-1]) * 0.01\n",
    "            self.b['b'+str(i)] = np.random.randn(self.total_layers[i],1)\n",
    "        \n",
    "        if verbose:\n",
    "            print('shape of weight(s) initialized : \\n ')\n",
    "            for i in self.W.values():\n",
    "                print(i.shape)\n",
    "            print('shape of bias(es) initialized : \\n ')\n",
    "            for i in self.b.values():\n",
    "                print(i.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    def forePropagate(self,train_x):\n",
    "        self.A['A0'] = train_x\n",
    "        a = self.activation_functions\n",
    "        \n",
    "        # populating Z and A with data\n",
    "        for i in range(1,len(self.total_layers)):\n",
    "            \n",
    "            # the formula for fore-propagation is z = W.X + b\n",
    "            self.Z[ 'Z'+str(i) ] = np.dot( self.W['W'+str(i)] , self.A['A'+str(i-1)] ) + self.b['b'+str(i)]\n",
    "          \n",
    "            # populating the activation dictionary with index values\n",
    "            \n",
    "            if a[i-1] == 'relu':\n",
    "                self.A['A'+str(i)] = relu( self.Z['Z'+str(i)] )\n",
    "            elif a[i-1] == 'sigmoid': \n",
    "                self.A['A'+str(i)] = sigmoid( self.Z['Z'+str(i)] )\n",
    "            elif a[i-1] == 'sigmoid_d':\n",
    "                self.A['A'+str(i)] = sigmoid_derivative( self.Z['Z'+str(i)] )\n",
    "            else:\n",
    "                self.A['A'+str(i)] = leaky_relu( self.Z['Z'+str(i)] )\n",
    "                \n",
    "    \n",
    "    def cost_calc(self,Y,loss_function = 'mse'):\n",
    "        \n",
    "        # the `m` used in cost functions represent the total number of training examples\n",
    "        if loss_function in ['mse','MSE']:\n",
    "            \n",
    "            # use mean squared error function     \n",
    "            loss = ( 1 / ( 2 * Y.shape[1])) * ( np.sum(np.square (  Y - self.A[ 'A'+str(len(self.total_layers)-1)])))\n",
    "            cost = np.squeeze(loss)\n",
    "         \n",
    "            self.costs.append(cost)\n",
    "            \n",
    "            \n",
    "        else : #['rmse','RMSE']:\n",
    "            \n",
    "            # use the root mean squared function\n",
    "            loss = np.sqrt( ( 1 / Y.shape[1]) * ( np.sum(np.square (  Y - self.A[ 'A'+str(len(self.total_layers)-1)])))) \n",
    "            cost = np.squeeze(loss)\n",
    "            \n",
    "            self.costs.append(cost)\n",
    "        \n",
    "#         elif loss_function in ['mae','MAE']:\n",
    "            \n",
    "#             use the mean absolute error function here \n",
    "#             self.costs.append( 1 / Y.shape[1] * (np.sum(  )) )  # you're going to have to do modulus here\n",
    "            \n",
    "#         else:\n",
    "            \n",
    "#             # use binary cross entropy\n",
    "#             self.costs.append( np.squeeze(-1 * np.sum( np.multiply( Y ,np.log(self.A[ 'A'+str(len(self.total_layers)-1)]) ) +\n",
    "#                                                         np.multiply( (1-Y),np.log(1-self.A[ 'A'+str(len(self.total_layers)-1)]) ) ) / Y.shape[1] ) )\n",
    "            \n",
    "            \n",
    "            \n",
    "    def back_prop(self,Y):\n",
    "        \n",
    "        # compute dA final layer \n",
    "        self.dA['dA'+str(len(self.total_layers)-1)] = -1 * np.divide(Y,self.A['A'+str(len(self.total_layers)-1)]) + np.divide(1-Y, 1-self.A['A'+str(len(self.total_layers)-1)])\n",
    "        \n",
    "        \n",
    "        # check for the final layer activation_func\n",
    "        if self.activation_functions[-1] == 'sigmoid':\n",
    "            self.dZ['dZ'+str(len(self.total_layers)-1)] = np.multiply( self.dA['dA'+str(len(self.total_layers)-1)] , sigmoid(self.Z['Z'+str(len(self.total_layers)-1)]) )\n",
    "        elif self.activation_functions[-1] == 'sigmoid_d':\n",
    "            self.dZ['dZ'+str(len(self.total_layers)-1)] = np.multiply( self.dA['dA'+str(len(self.total_layers)-1)] , sigmoid_derivative(self.Z['Z'+str(len(self.total_layers)-1)]) )\n",
    "        elif self.activation_functions[-1] == 'relu':\n",
    "            self.dZ['dZ'+str(len(self.total_layers)-1)] = np.multiply( self.dA['dA'+str(len(self.total_layers)-1)] , relu(self.Z['Z'+str(len(self.total_layers)-1)]) )\n",
    "        else:\n",
    "            self.dZ['dZ'+str(len(self.total_layers)-1)] = np.multiply( self.dA['dA'+str(len(self.total_layers)-1)] , leaky_relu(self.Z['Z'+str(len(self.total_layers)-1)]) )\n",
    "        \n",
    "        # get dW final layer\n",
    "        self.dW['dW'+str(len(self.total_layers)-1)] = ( 1 / Y.shape[1] ) * np.dot( self.dZ['dZ'+str(len(self.total_layers)-1)] , self.A['A'+str(len(self.total_layers)-2)].T )\n",
    "        \n",
    "        # get db final layer \n",
    "        self.db['db'+str(len(self.total_layers)-1)] = (1/Y.shape[1]) * np.sum(self.dZ['dZ'+str(len(self.total_layers)-1)],axis = 1, keepdims = True)\n",
    "        \n",
    "        self.dA['dA'+str(len(self.total_layers)-2)] = np.dot(self.W['W'+str(len(self.total_layers)-1)].T , self.dZ['dZ'+str(len(self.total_layers)-1)] )\n",
    "        \n",
    "        \n",
    "        # loop over the number of hidden layers + 1 in the network in reverse and find weights and biases for them\n",
    "        for i in reversed(range(1,len(self.total_layers)-1)):\n",
    "            \n",
    "            # check for DZ and get it done\n",
    "            if self.activation_functions[i] == 'sigmoid':\n",
    "                self.dZ['dZ'+str(i)] = np.multiply( self.dA['dA'+str(i)] , sigmoid(self.Z['Z'+str(i)]) )\n",
    "            elif self.activation_functions[i] == 'sigmoid_d':\n",
    "                self.dZ['dZ'+str(i)] = np.multiply( self.dA['dA'+str(i)] , sigmoid_derivative(self.Z['Z'+str(i)]) )\n",
    "            elif self.activation_functions[i] == 'relu':\n",
    "                self.dZ['dZ'+str(i)] = np.multiply( self.dA['dA'+str(i)] , relu(self.Z['Z'+str(i)]) )\n",
    "            else:\n",
    "                self.dZ['dZ'+str(i)] = np.multiply( self.dA['dA'+str(i)] , leaky_relu(self.Z['Z'+str(i)]) )\n",
    "      \n",
    "            \n",
    "            self.dW['dW'+str(i)] = np.dot(self.dZ['dZ'+str(i)], self.A['A'+str(i - 1)].T) / Y.shape[1]\n",
    "            self.db['db'+str(i)] = np.sum(self.dZ['dZ'+str(i)], axis = 1, keepdims = True) / Y.shape[1]\n",
    "            self.dA['dA'+str(i - 1)] = np.dot(self.W['W'+str(i)].T, self.dZ['dZ'+str(i)])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def param_update(self):\n",
    "        for i in range(1,len(self.total_layers)):\n",
    "            self.W['W'+str(i)] -= self.learning_rate * self.dW['dW'+str(i)]\n",
    "            self.b['b'+str(i)] -= self.learning_rate * self.db['db'+str(i)]\n",
    "            \n",
    "            \n",
    "            \n",
    "    def fit(self,xtrain,ytrain,epoch = 50, learning_rate = 0.001,lr_decay_rate = 0.9, verbose = 0,lr_decay = False,lr_decay_epoch = 10,decay_stop = 50, loss_function = 'mse'):\n",
    "#         tx = xtrain.T\n",
    "#         ty = ytrain.T\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.init_Params()\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            \n",
    "            self.forePropagate(tx)\n",
    "            \n",
    "            self.cost_calc(ty,loss_function = loss_function)\n",
    "            \n",
    "            self.back_prop(ty)\n",
    "            \n",
    "            self.param_update()\n",
    "            \n",
    "            self.lr_change.append(learning_rate)\n",
    "            \n",
    "            if lr_decay and i % lr_decay_epoch == 0 and decay_stop > 0:\n",
    "                self.learning_rate = self.learning_rate * lr_decay_rate\n",
    "                self.lr_change.append(self.learning_rate)\n",
    "                decay_stop -= 1\n",
    "                \n",
    "            if verbose and i % verbose == 0 and str( self.costs[-1] ) != 'nan':\n",
    "                \n",
    "                print(f'epoch {i} : \\t cost = {self.costs[-1]}')\n",
    "                print(f'learning rate / alpha \\t{self.learning_rate}\\n')\n",
    "                \n",
    "                \n",
    "            \n",
    "                \n",
    "        \n",
    "    \n",
    "    def predict(self,xtest):\n",
    "        \n",
    "        # we fore prop at first and return the last A\n",
    "        self.forePropagate(xtest)\n",
    "        \n",
    "        return self.A['A'+str(len(self.total_layers)-1)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def mse_model_eval(self,ytest,ypreds):\n",
    "        \n",
    "        # compute the Mean Squared Error with y-preds and y-test\n",
    "        try:\n",
    "            loss = ( 1 / ( 2 * ypreds.shape[1])) * ( np.sum(np.square (  ypreds - self.A[ 'A'+str(len(self.total_layers)-1)])))\n",
    "            return np.squeeze(loss)\n",
    "        except:\n",
    "            print('Please check the indices and re-try')\n",
    "            \n",
    "            \n",
    "    \n",
    "    def plot_cost_to_epoch(self):\n",
    "        self.costs = [self.costs[x] for x in range(1,len(self.costs)) if str(self.costs[x]) != 'nan' ]\n",
    "        plt.plot(self.costs, color = 'r')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def save_model(self,path,file = 'model'):\n",
    "        \n",
    "        model = {'w':self.W,'b':self.b,'lr':self.learning_rate,'actvns':self.activation_functions,\n",
    "                        'hl':self.hidden_Layersi,'tl':self.total_layers\n",
    "                        }\n",
    "        with open(file,'wb') as file :\n",
    "            pickle.dump(model,file+'.dat')\n",
    "        \n",
    "        \n",
    "    \n",
    "    def use_model(self,path):\n",
    "        try:\n",
    "            with open(path,'rb') as file:\n",
    "                model = pickle.load(file)\n",
    "                self.W = model['w']\n",
    "                self.b = model['b']\n",
    "                self.activation_functions = model['actvns']\n",
    "                self.total_layers = model['tl']\n",
    "                self.hidden_Layers = model['hl']\n",
    "                self.learning_rate = model['lr']\n",
    "        except:\n",
    "            print(f\"unable to open {path}\\n check if you've added the file extension(.dat) with the file path\")\n",
    "    \n",
    "    \n",
    "    def auto_model_setup(self,seed):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ann()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_hl([3,2],activations = ['relu','relu','sigmoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13234)\n",
    "tx = np.random.random((3,100))\n",
    "ty = np.random.random((1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network structure update :[3, 3, 2, 1]\n",
      " feature(s) : 3 \n",
      " label(s) : 1 \n",
      " hidden layers : [3, 2]\n"
     ]
    }
   ],
   "source": [
    "model.register_training_data(np.random.random((3,100)),np.random.random((1,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[-0.01298571, -0.00092539,  0.00070074],\n",
      "       [ 0.01855052,  0.0137026 , -0.0018258 ],\n",
      "       [-0.01170023,  0.01027954, -0.00834468]]), 'W2': array([[-0.01505343,  0.00870126,  0.01223903],\n",
      "       [-0.02231902,  0.00028256,  0.00310356]]), 'W3': array([[0.00538658, 0.01067838]])}\n",
      "\n",
      "{'b1': array([[ 0.18779336],\n",
      "       [-0.64842091],\n",
      "       [ 0.82941762]]), 'b2': array([[0.55446558],\n",
      "       [0.29317822]]), 'b3': array([[-1.73308753]])}\n"
     ]
    }
   ],
   "source": [
    "model.forePropagate(tx)\n",
    "\n",
    "print(model.W)\n",
    "print()\n",
    "print(model.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cost_calc(ty,loss_function = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.back_prop(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dW3': array([[-0.61511431, -0.31935751]]), 'dW2': array([[-0.00167989,  0.        , -0.00762725],\n",
      "       [-0.00370527,  0.        , -0.01682312]]), 'dW1': array([[ 5.23612320e-05,  4.75908018e-05,  5.90970276e-05],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "       [-7.11381417e-05, -6.43758711e-05, -7.94984026e-05]])}\n"
     ]
    }
   ],
   "source": [
    "print(model.dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.param_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : \t cost = 19.000877010743412\n",
      "learning rate / alpha \t0.01\n",
      "\n",
      "epoch 10 : \t cost = 14.339316421595209\n",
      "learning rate / alpha \t0.01\n",
      "\n",
      "epoch 20 : \t cost = 10.694453982645786\n",
      "learning rate / alpha \t0.01\n",
      "\n",
      "epoch 30 : \t cost = 7.7821272227981115\n",
      "learning rate / alpha \t0.01\n",
      "\n",
      "epoch 40 : \t cost = 5.434218233834228\n",
      "learning rate / alpha \t0.01\n",
      "\n",
      "epoch 50 : \t cost = 3.555939741549811\n",
      "learning rate / alpha \t0.01\n",
      "\n",
      "epoch 60 : \t cost = 2.0992335993447875\n",
      "learning rate / alpha \t0.01\n",
      "\n",
      "epoch 70 : \t cost = 1.041598958144907\n",
      "learning rate / alpha \t0.01\n",
      "\n",
      "epoch 80 : \t cost = 0.3638770114588264\n",
      "learning rate / alpha \t0.01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-328-d6e922ad6d89>:135: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.dA['dA'+str(len(self.total_layers)-1)] = -1 * np.divide(Y,self.A['A'+str(len(self.total_layers)-1)]) + np.divide(1-Y, 1-self.A['A'+str(len(self.total_layers)-1)])\n",
      "<ipython-input-328-d6e922ad6d89>:166: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.dZ['dZ'+str(i)] = np.multiply( self.dA['dA'+str(i)] , relu(self.Z['Z'+str(i)]) )\n"
     ]
    }
   ],
   "source": [
    "model.fit(tx,ty,verbose=10,lr_decay=False,learning_rate=0.01,epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.plot_cost_to_epoch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20e2590dd00>]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASEklEQVR4nO3cf6zdd33f8edr9uxCJ4fEcboQu7NZzIpBLQ13XtgP1pESHMRwWmWao0pYq4W1iGyAxtpEiDLyV9NWS4uSRY2ajBBVJDSwcscEWZpkSEgk5HgrxHZwcxsouU3aXBQv5YcguH3vj/Nxcj+XY99zf+C7e/18SEf3fN/f9/fjz+d+b+7rfL/n3KSqkCTppL+10hOQJP3/xWCQJHUMBklSx2CQJHUMBklSZ/1KT2A5nH/++bV9+/aVnoYkrSqHDh36ZlVtmVtfE8Gwfft2BoPBSk9DklaVJH82qu6tJElSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSZ6xgSLInybEkU0muG7F/Y5J72v5Hkmxv9c1JHkry7SQ3zznmDUkea8d8JEnm7H9/kkpy/uKXJ0laqHmDIck64BbgCmAXcHWSXXPaDgDHq+pi4Cbgxlb/HvBB4P0jhr4VOAjsbI89s/7NbcBbgG8sZDGSpKUb54phNzBVVU9W1QvA3cDeOT17gTvb83uBy5Kkqr5TVV9gGBAvSnIhsKmqvlhVBXwMuHJWy03ArwC14BVJkpZknGC4CHhq1vZ0q43sqaoTwPPA5nnGnB41ZpJ3AH9eVV8+3aSSHEwySDKYmZkZYxmSpHGMEwwZUZv7Sn6cnnn7k7wc+ADwa/NNqqpuq6qJqprYsmXLfO2SpDGNEwzTwLZZ21uBp0/Vk2Q9cA7w3Dxjbh0x5t8HdgBfTvL1Vv/fSf7uGPOUJC2DcYLhUWBnkh1JNgD7gMk5PZPA/vb8KuDB9t7BSFX1DPCtJJe2TyO9E/h0VT1WVRdU1faq2s4wQC6pqr9Y2LIkSYu1fr6GqjqR5FrgPmAdcEdVHUlyAzCoqkngduCuJFMMrxT2nTy+vfLfBGxIciVweVUdBa4BPgq8DPhse0iSVlhO88J+1ZiYmKjBYLDS05CkVSXJoaqamFv3L58lSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUGSsYkuxJcizJVJLrRuzfmOSetv+RJNtbfXOSh5J8O8nNc455Q5LH2jEfSZJW/80kX03ylST/Lckrlr5MSdK45g2GJOuAW4ArgF3A1Ul2zWk7AByvqouBm4AbW/17wAeB948Y+lbgILCzPfa0+v3A66rqp4E/Aa5fyIIkSUszzhXDbmCqqp6sqheAu4G9c3r2Ane25/cClyVJVX2nqr7AMCBelORCYFNVfbGqCvgYcCVAVf3PqjrRWh8Gti5mYZKkxRknGC4Cnpq1Pd1qI3vaL/Xngc3zjDk9z5gAvwx8dow5SpKWyTjBkBG1WkTPgvqTfAA4Afz+yAGSg0kGSQYzMzOn+ackSQsxTjBMA9tmbW8Fnj5VT5L1wDnAc/OMOfsWUTdmkv3A24FfareafkhV3VZVE1U1sWXLljGWIUkaxzjB8CiwM8mOJBuAfcDknJ5JYH97fhXw4Kl+oQNU1TPAt5Jc2j6N9E7g0zD8BBTwq8A7quq7C1qNJGnJ1s/XUFUnklwL3AesA+6oqiNJbgAGVTUJ3A7clWSK4ZXCvpPHJ/k6sAnYkORK4PKqOgpcA3wUeBnD9xFOvpdwM7ARuL99gvXhqvq3y7BWSdIYcpoX9qvGxMREDQaDlZ6GJK0qSQ5V1cTcun/5LEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqjBUMSfYkOZZkKsl1I/ZvTHJP2/9Iku2tvjnJQ0m+neTmOce8Iclj7ZiPJEmrn5fk/iRPtK/nLn2ZkqRxzRsMSdYBtwBXALuAq5PsmtN2ADheVRcDNwE3tvr3gA8C7x8x9K3AQWBne+xp9euAB6pqJ/BA25YknSHrx+jZDUxV1ZMASe4G9gJHZ/XsBf5Te34vcHOSVNV3gC8kuXj2gEkuBDZV1Rfb9seAK4HPtrF+rrXeCfwv4FcXurBxfPi/H+Ho03/1oxhaks6IXa/cxIf+5WuXdcxxbiVdBDw1a3u61Ub2VNUJ4Hlg8zxjTp9izJ+oqmfaWM8AF4waIMnBJIMkg5mZmTGWIUkaxzhXDBlRq0X0LKX/h5urbgNuA5iYmFjQsSctd8pK0lowzhXDNLBt1vZW4OlT9SRZD5wDPDfPmFtPMeZftltNJ285PTvGHCVJy2ScYHgU2JlkR5INwD5gck7PJLC/Pb8KeLCqTvkqvt0i+laSS9unkd4JfHrEWPtn1SVJZ8C8t5Kq6kSSa4H7gHXAHVV1JMkNwKCqJoHbgbuSTDG8Uth38vgkXwc2ARuSXAlcXlVHgWuAjwIvY/im82fbIb8OfCLJAeAbwL9ajoVKksaT07ywXzUmJiZqMBis9DQkaVVJcqiqJubW/ctnSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdcYKhiR7khxLMpXkuhH7Nya5p+1/JMn2Wfuub/VjSd46q/6eJIeTHEny3ln11yd5OMkfJxkk2b20JUqSFmLeYEiyDrgFuALYBVydZNectgPA8aq6GLgJuLEduwvYB7wW2AP8lyTrkrwOeBewG/gZ4O1JdraxfgP4cFW9Hvi1ti1JOkPGuWLYDUxV1ZNV9QJwN7B3Ts9e4M72/F7gsiRp9bur6vtV9TVgqo33GuDhqvpuVZ0APg/8Qju+gE3t+TnA04tbmiRpMcYJhouAp2ZtT7fayJ72i/55YPNpjj0MvCnJ5iQvB94GbGs97wV+M8lTwG8B1y9kQZKkpRknGDKiVmP2jKxX1eMMbzfdD3wO+DJwou2/BnhfVW0D3gfcPnJSycH2HsRgZmZm/lVIksYyTjBM89KreYCt/PDtnRd7kqxneAvoudMdW1W3V9UlVfWm1vtE69kPfKo9/wOGt55+SFXdVlUTVTWxZcuWMZYhSRrHOMHwKLAzyY4kGxi+mTw5p2eS4S90gKuAB6uqWn1f+9TSDmAn8CWAJBe0rz8J/CLw8Xb808A/b8/fzEuBIUk6A9bP11BVJ5JcC9wHrAPuqKojSW4ABlU1yfB2z11Jphi++t/Xjj2S5BPAUYa3it5dVX/dhv5kks3AD1r9eKu/C/idduXxPeDgci1WkjS/DF/Yr24TExM1GAxWehqStKokOVRVE3Pr/uWzJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKkzVjAk2ZPkWJKpJNeN2L8xyT1t/yNJts/ad32rH0vy1ln19yQ5nORIkvfOGe/ftf4jSX5j8cuTJC3U+vkakqwDbgHeAkwDjyaZrKqjs9oOAMer6uIk+4AbgX+dZBewD3gt8Ergj5K8GngN8C5gN/AC8Lkk/6OqnkjyL4C9wE9X1feTXLBsq5UkzWucK4bdwFRVPVlVLwB3M/zFPdte4M72/F7gsiRp9bur6vtV9TVgqo33GuDhqvpuVZ0APg/8Qjv+GuDXq+r7AFX17OKXJ0laqHGC4SLgqVnb0602sqf9on8e2HyaYw8Db0qyOcnLgbcB21rPq4F/1m5JfT7JPxw1qSQHkwySDGZmZsZYhiRpHOMEQ0bUasyekfWqepzh7ab7gc8BXwZOtP3rgXOBS4H/CHyiXX3MHeS2qpqoqoktW7aMsQxJ0jjGCYZpXno1D7AVePpUPUnWA+cAz53u2Kq6vaouqao3td4nZo31qRr6EvA3wPkLWZQkafHGCYZHgZ1JdiTZwPDN5Mk5PZPA/vb8KuDBqqpW39c+tbQD2Al8CeDkm8pJfhL4ReDj7fg/BN7c9r0a2AB8c3HLkyQt1LyfSqqqE0muBe4D1gF3VNWRJDcAg6qaBG4H7koyxfDV/7527JEknwCOMrxV9O6q+us29CeTbAZ+0OrHW/0O4I4khxl+Yml/CxlJ0hmQtfA7d2JiogaDwUpPQ5JWlSSHqmpibt2/fJYkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVInVbXSc1iyJDPAny3y8POBby7jdFYD13x2cM1nh6Ws+e9V1Za5xTURDEuRZFBVEys9jzPJNZ8dXPPZ4UexZm8lSZI6BoMkqWMwwG0rPYEV4JrPDq757LDsaz7r32OQJPW8YpAkdQwGSVLnrA6GJHuSHEsyleS6lZ7PckiyLclDSR5PciTJe1r9vCT3J3mifT231ZPkI+178JUkl6zsChYvybok/yfJZ9r2jiSPtDXfk2RDq29s21Nt//aVnPdiJXlFknuTfLWd7zeu9fOc5H3t5/pwko8n+bG1dp6T3JHk2SSHZ9UWfF6T7G/9TyTZv5A5nLXBkGQdcAtwBbALuDrJrpWd1bI4AfyHqnoNcCnw7rau64AHqmon8EDbhuH6d7bHQeDWMz/lZfMe4PFZ2zcCN7U1HwcOtPoB4HhVXQzc1PpWo98BPldVPwX8DMO1r9nznOQi4N8DE1X1OmAdsI+1d54/CuyZU1vQeU1yHvAh4B8Bu4EPnQyTsVTVWfkA3gjcN2v7euD6lZ7Xj2CdnwbeAhwDLmy1C4Fj7fnvAlfP6n+xbzU9gK3tP5g3A58BwvCvQdfPPd/AfcAb2/P1rS8rvYYFrncT8LW5817L5xm4CHgKOK+dt88Ab12L5xnYDhxe7HkFrgZ+d1a965vvcdZeMfDSD9lJ0622ZrRL558FHgF+oqqeAWhfL2hta+X78NvArwB/07Y3A/+3qk607dnrenHNbf/zrX81eRUwA/zXdvvs95L8OGv4PFfVnwO/BXwDeIbheTvE2j7PJy30vC7pfJ/NwZARtTXz2d0kfwf4JPDeqvqr07WOqK2q70OStwPPVtWh2eURrTXGvtViPXAJcGtV/SzwHV66vTDKql9zuxWyF9gBvBL4cYa3UuZaS+d5Pqda45LWfjYHwzSwbdb2VuDpFZrLskrytxmGwu9X1ada+S+TXNj2Xwg82+pr4fvwT4B3JPk6cDfD20m/DbwiyfrWM3tdL6657T8HeO5MTngZTAPTVfVI276XYVCs5fP888DXqmqmqn4AfAr4x6zt83zSQs/rks732RwMjwI72ycaNjB8E2tyhee0ZEkC3A48XlX/edauSeDkJxP2M3zv4WT9ne3TDZcCz5+8ZF0tqur6qtpaVdsZnscHq+qXgIeAq1rb3DWf/F5c1fpX1SvJqvoL4Kkk/6CVLgOOsobPM8NbSJcmeXn7OT+55jV7nmdZ6Hm9D7g8ybntSuvyVhvPSr/JssJv8LwN+BPgT4EPrPR8lmlN/5ThJeNXgD9uj7cxvLf6APBE+3pe6w/DT2f9KfAYw098rPg6lrD+nwM+056/CvgSMAX8AbCx1X+sbU+1/a9a6Xkvcq2vBwbtXP8hcO5aP8/Ah4GvAoeBu4CNa+08Ax9n+B7KDxi+8j+wmPMK/HJb+xTwbxYyB/+XGJKkztl8K0mSNILBIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpM7/AwBErUk1n52YAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.lr_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(324)\n",
    "testx = np.random.random((3,100))\n",
    "testy = np.random.random((1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = model.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "print(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mse_model_eval(testy,yp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
