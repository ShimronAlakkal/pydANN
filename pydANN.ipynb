{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pydANN ( python deep Artificial Neural Network )\n",
    "\n",
    "is a free and open source python library to implement the Machine Learning algorithm of neural networks\n",
    "The network can be as simple as a sinle layer perceptron net or a multi-layer deep neural net.\n",
    "THe design and modifications of this library is posted [here](https://www.github.com/ShimronAlakkal)\n",
    "\n",
    "\n",
    "### 1 - Packages\n",
    "\n",
    "These are some of the most important packages that you're going to need in order to use ***```pydANN```***\n",
    "\n",
    "- [numpy](www.numpy.org) (or numeric python) is the main package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a library to plot graphs -- which are optional -- in Python.\n",
    "- [pickle](https://docs.python.org/3/library/pickle.html) is the library pydANN uses to save your trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom tools (functions) that are called inside of the activation layer.\n",
    "To specify the activation function for a layer use `activation_specific = f` with `addHL()`,  where `f` is a list, of length of hidden layers + 1, and each index with a custom function name.\n",
    "If there is a mismatch in the input activation_specifics, the model is going to auto adjust the activation with the last ones from your input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1 / 1 + np.exp(-Z)\n",
    "\n",
    "def leaky_relu(Z):\n",
    "    return np.maximum(0.1*Z)\n",
    "\n",
    "def sigmoid_derivative(Z):\n",
    "    return sigmoid(Z) * ( 1 - sigmoid(Z) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ann:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hidden_Layers = [3,2]\n",
    "        self.total_layers = []\n",
    "        self.learning_rate = 0.001\n",
    "        self.epoch = 0\n",
    "        self.W = {}\n",
    "        self.b = {}\n",
    "        self.Z = {}\n",
    "        self.A = {}\n",
    "        self.activation_functions = []\n",
    "        self.costs = [0]\n",
    "        self.dW = {}\n",
    "        self.db = {}\n",
    "        self.dZ = {}\n",
    "        self.dA = {}\n",
    "        self.lr_change = []\n",
    "        \n",
    "    \n",
    "    \n",
    "    def add_hl(self,hl,activations ):\n",
    "        self.hidden_Layers.clear()\n",
    "        self.hidden_Layers = hl\n",
    "        \n",
    "        # settingf the activations\n",
    "        if len(activations) == len(hl)+1:\n",
    "            self.activation_functions = activations\n",
    "        else:\n",
    "            print('Passed activations should be 1 more than the HL length \\n recall the function to override HL')\n",
    "                \n",
    "        \n",
    "    def dispose_model(self):\n",
    "        self.total_layers.clear()\n",
    "        self.hidden_Layers.clear()\n",
    "        self.costs.clear()\n",
    "        self.lr_change.clear()\n",
    "        self.Z.clear()\n",
    "        self.W.clear()\n",
    "        self.b.clear()\n",
    "        self.db.clear()\n",
    "        self.dW.clear()\n",
    "        self.dZ.clear()\n",
    "        self.dA.clear()\n",
    "            \n",
    "    def register_training_data(self,train_x,train_y):\n",
    "        self.total_layers.clear()\n",
    "        self.total_layers.append(train_x.shape[0])\n",
    "        for i in self.hidden_Layers:\n",
    "            self.total_layers.append(i)\n",
    "       \n",
    "        # network structure\n",
    "        self.total_layers.append(train_y.shape[0])\n",
    "        print(f\"Network structure update :{self.total_layers}\\n feature(s) : {self.total_layers[0]} \\n label(s) : {self.total_layers[-1]} \\n hidden layers : {self.hidden_Layers}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def init_Params(self,verbose = False):\n",
    "        \n",
    "        # creating the weights and biases with seed(1)\n",
    "        np.random.seed(144)\n",
    "        for i in range(1,len(self.total_layers)):\n",
    "            \n",
    "            self.W['W'+str(i)] = np.random.randn(self.total_layers[i],self.total_layers[i-1]) * 0.01\n",
    "            self.b['b'+str(i)] = np.random.randn(self.total_layers[i],1)\n",
    "        \n",
    "        if verbose:\n",
    "            print('shape of weight(s) initialized : \\n ')\n",
    "            for i in self.W.values():\n",
    "                print(i.shape)\n",
    "            print('shape of bias(es) initialized : \\n ')\n",
    "            for i in self.b.values():\n",
    "                print(i.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    def forePropagate(self,train_x):\n",
    "        self.A['A0'] = train_x\n",
    "        a = self.activation_functions\n",
    "        \n",
    "        # populating Z and A with data\n",
    "        for i in range(1,len(self.total_layers)):\n",
    "            \n",
    "            # the formula for fore-propagation is z = W.X + b\n",
    "            self.Z[ 'Z'+str(i) ] = np.dot( self.W['W'+str(i)] , self.A['A'+str(i-1)] ) + self.b['b'+str(i)]\n",
    "          \n",
    "            # populating the activation dictionary with index values\n",
    "            \n",
    "            if a[i-1] == 'relu':\n",
    "                self.A['A'+str(i)] = relu( self.Z['Z'+str(i)] )\n",
    "            elif a[i-1] == 'sigmoid': \n",
    "                self.A['A'+str(i)] = sigmoid( self.Z['Z'+str(i)] )\n",
    "            elif a[i-1] == 'sigmoid_d':\n",
    "                self.A['A'+str(i)] = sigmoid_derivative( self.Z['Z'+str(i)] )\n",
    "            else:\n",
    "                self.A['A'+str(i)] = leaky_relu( self.Z['Z'+str(i)] )\n",
    "                \n",
    "    \n",
    "    def cost_calc(self,Y,loss_function ):\n",
    "        \n",
    "        # the `m` used in cost functions represent the total number of training examples\n",
    "        if loss_function in ['mse','MSE']:\n",
    "            \n",
    "            # use mean squared error function     \n",
    "            loss = ( 1 / ( 2 * Y.shape[1])) * ( np.sum(np.square (  Y - self.A[ 'A'+str(len(self.total_layers)-1)])))\n",
    "            cost = np.squeeze(loss)\n",
    "         \n",
    "            self.costs.append(cost)\n",
    "            \n",
    "            \n",
    "        else : #['rmse','RMSE']:\n",
    "            \n",
    "            # use the root mean squared function\n",
    "            loss = np.sqrt( ( 1 / Y.shape[1]) * ( np.sum(np.square (  Y - self.A[ 'A'+str(len(self.total_layers)-1)])))) \n",
    "            cost = np.squeeze(loss)\n",
    "            \n",
    "            self.costs.append(cost)\n",
    "        \n",
    "#         elif loss_function in ['mae','MAE']:\n",
    "            \n",
    "#             use the mean absolute error function here \n",
    "#             self.costs.append( 1 / Y.shape[1] * (np.sum(  )) )  # you're going to have to do modulus here\n",
    "            \n",
    "#         else:\n",
    "            \n",
    "#             # use binary cross entropy\n",
    "#             self.costs.append( np.squeeze(-1 * np.sum( np.multiply( Y ,np.log(self.A[ 'A'+str(len(self.total_layers)-1)]) ) +\n",
    "#                                                         np.multiply( (1-Y),np.log(1-self.A[ 'A'+str(len(self.total_layers)-1)]) ) ) / Y.shape[1] ) )\n",
    "            \n",
    "            \n",
    "            \n",
    "    def back_prop(self,Y):\n",
    "        \n",
    "        # compute dA final layer \n",
    "        self.dA['dA'+str(len(self.total_layers)-1)] =  (-1 * np.divide(Y,self.A['A'+str(len(self.total_layers)-1)])) - np.divide(1-Y, 1-self.A['A'+str(len(self.total_layers)-1)])\n",
    "        \n",
    "        \n",
    "        # check for the final layer activation_func\n",
    "        if self.activation_functions[-1] == 'sigmoid':\n",
    "            self.dZ['dZ'+str(len(self.total_layers)-1)] = np.multiply( self.dA['dA'+str(len(self.total_layers)-1)] , sigmoid(self.Z['Z'+str(len(self.total_layers)-1)]) )\n",
    "        elif self.activation_functions[-1] == 'sigmoid_d':\n",
    "            self.dZ['dZ'+str(len(self.total_layers)-1)] = np.multiply( self.dA['dA'+str(len(self.total_layers)-1)] , sigmoid_derivative(self.Z['Z'+str(len(self.total_layers)-1)]) )\n",
    "        elif self.activation_functions[-1] == 'relu':\n",
    "            self.dZ['dZ'+str(len(self.total_layers)-1)] = np.multiply( self.dA['dA'+str(len(self.total_layers)-1)] , relu(self.Z['Z'+str(len(self.total_layers)-1)]) )\n",
    "        else:\n",
    "            self.dZ['dZ'+str(len(self.total_layers)-1)] = np.multiply( self.dA['dA'+str(len(self.total_layers)-1)] , leaky_relu(self.Z['Z'+str(len(self.total_layers)-1)]) )\n",
    "        \n",
    "        # get dW final layer\n",
    "        self.dW['dW'+str(len(self.total_layers)-1)] = ( 1 / Y.shape[1] ) * np.dot( self.dZ['dZ'+str(len(self.total_layers)-1)] , self.A['A'+str(len(self.total_layers)-2)].T )\n",
    "        \n",
    "        # get db final layer \n",
    "        self.db['db'+str(len(self.total_layers)-1)] = (1/Y.shape[1]) * np.sum(self.dZ['dZ'+str(len(self.total_layers)-1)],axis = 1, keepdims = True)\n",
    "        \n",
    "        self.dA['dA'+str(len(self.total_layers)-2)] = np.dot(self.W['W'+str(len(self.total_layers)-1)].T , self.dZ['dZ'+str(len(self.total_layers)-1)] )\n",
    "        \n",
    "        \n",
    "        # loop over the number of hidden layers + 1 in the network in reverse and find weights and biases for them\n",
    "        for i in reversed(range(1,len(self.total_layers)-1)):\n",
    "            \n",
    "            # check for DZ and get it done\n",
    "            if self.activation_functions[i] == 'sigmoid':\n",
    "                self.dZ['dZ'+str(i)] = np.multiply( self.dA['dA'+str(i)] , sigmoid(self.Z['Z'+str(i)]) )\n",
    "            elif self.activation_functions[i] == 'sigmoid_d':\n",
    "                self.dZ['dZ'+str(i)] = np.multiply( self.dA['dA'+str(i)] , sigmoid_derivative(self.Z['Z'+str(i)]) )\n",
    "            elif self.activation_functions[i] == 'relu':\n",
    "                self.dZ['dZ'+str(i)] = np.multiply( self.dA['dA'+str(i)] , relu(self.Z['Z'+str(i)]) )\n",
    "            else:\n",
    "                self.dZ['dZ'+str(i)] = np.multiply( self.dA['dA'+str(i)] , leaky_relu(self.Z['Z'+str(i)]) )\n",
    "      \n",
    "            \n",
    "            self.dW['dW'+str(i)] = np.dot(self.dZ['dZ'+str(i)], self.A['A'+str(i - 1)].T) / Y.shape[1]\n",
    "            self.db['db'+str(i)] = np.sum(self.dZ['dZ'+str(i)], axis = 1, keepdims = True) / Y.shape[1]\n",
    "            self.dA['dA'+str(i - 1)] = np.dot(self.W['W'+str(i)].T, self.dZ['dZ'+str(i)])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def param_update(self):\n",
    "        for i in range(1,len(self.total_layers)):\n",
    "            self.W['W'+str(i)] -= self.learning_rate * self.dW['dW'+str(i)]\n",
    "            self.b['b'+str(i)] -= self.learning_rate * self.db['db'+str(i)]\n",
    "            \n",
    "            \n",
    "            \n",
    "    def fit(self,xtrain,ytrain,epoch = 50, learning_rate = 0.001,lr_decay_rate = 0.9, verbose = 0,lr_decay = False,lr_decay_epoch = 10,decay_stop = 50, loss_function = 'mse'):\n",
    "#         tx = xtrain.T\n",
    "#         ty = ytrain.T\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.init_Params()\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            \n",
    "            self.forePropagate(tx)\n",
    "            \n",
    "            self.cost_calc(ty,loss_function = loss_function)\n",
    "            \n",
    "            self.back_prop(ty)\n",
    "            \n",
    "            self.param_update()\n",
    "            \n",
    "            self.lr_change.append(learning_rate)\n",
    "            \n",
    "            if lr_decay and i % lr_decay_epoch == 0 and decay_stop > 0:\n",
    "                self.learning_rate = self.learning_rate * lr_decay_rate\n",
    "                self.lr_change.append(self.learning_rate)\n",
    "                print(self.learning_rate,'\\t is the learning rate now')\n",
    "                decay_stop -= 1\n",
    "                \n",
    "            if verbose and i % verbose == 0 and str( self.costs[-1] ) != 'nan':\n",
    "                \n",
    "                print(f'epoch {i} : \\t cost = {self.costs[-1]}')\n",
    "                print(f'learning rate / alpha \\t{self.learning_rate}\\n')\n",
    "                \n",
    "                \n",
    "            \n",
    "                \n",
    "        \n",
    "    \n",
    "    def predict(self,xtest):\n",
    "        \n",
    "        # we fore prop at first and return the last A\n",
    "        self.forePropagate(xtest)\n",
    "        \n",
    "        return self.A['A'+str(len(self.total_layers)-1)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def mse_model_eval(self,ytest,ypreds):\n",
    "        \n",
    "        # compute the Mean Squared Error with y-preds and y-test\n",
    "        try:\n",
    "            loss = ( 1 / ( 2 * ypreds.shape[1])) * ( np.sum(np.square (  ypreds - self.A[ 'A'+str(len(self.total_layers)-1)])))\n",
    "            return np.squeeze(loss)\n",
    "        except:\n",
    "            print('Please check the indices and re-try')\n",
    "            \n",
    "            \n",
    "    \n",
    "    def plot_cost_to_epoch(self):\n",
    "        self.costs = [self.costs[x] for x in range(1,len(self.costs)) if str(self.costs[x]) != 'nan' ]\n",
    "        plt.plot(self.costs, color = 'r')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def save_model(self,path,file = 'model'):\n",
    "        \n",
    "        model = {'w':self.W,'b':self.b,'lr':self.learning_rate,'actvns':self.activation_functions,\n",
    "                        'hl':self.hidden_Layersi,'tl':self.total_layers\n",
    "                        }\n",
    "        with open(file,'wb') as file :\n",
    "            pickle.dump(model,file+'.dat')\n",
    "        \n",
    "        \n",
    "    \n",
    "    def use_model(self,path):\n",
    "        try:\n",
    "            with open(path,'rb') as file:\n",
    "                model = pickle.load(file)\n",
    "                self.W = model['w']\n",
    "                self.b = model['b']\n",
    "                self.activation_functions = model['actvns']\n",
    "                self.total_layers = model['tl']\n",
    "                self.hidden_Layers = model['hl']\n",
    "                self.learning_rate = model['lr']\n",
    "        except:\n",
    "            print(f\"unable to open {path}\\n check if you've added the file extension(.dat) with the file path\")\n",
    "    \n",
    "    \n",
    "    def auto_model_setup(self,seed):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ann()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_hl([3,2],activations = ['sigmoid','sigmoid','sigmoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13234)\n",
    "tx = np.random.random((3,100))\n",
    "ty = np.random.random((1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network structure update :[3, 3, 2, 1]\n",
      " feature(s) : 3 \n",
      " label(s) : 1 \n",
      " hidden layers : [3, 2]\n"
     ]
    }
   ],
   "source": [
    "model.register_training_data(np.random.random((3,100)),np.random.random((1,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[-0.01298571, -0.00092539,  0.00070074],\n",
      "       [ 0.01855052,  0.0137026 , -0.0018258 ],\n",
      "       [-0.01170023,  0.01027954, -0.00834468]]), 'W2': array([[-0.01505343,  0.00870126,  0.01223903],\n",
      "       [-0.02231902,  0.00028256,  0.00310356]]), 'W3': array([[0.00538658, 0.01067838]])}\n",
      "\n",
      "{'b1': array([[ 0.18779336],\n",
      "       [-0.64842091],\n",
      "       [ 0.82941762]]), 'b2': array([[0.55446558],\n",
      "       [0.29317822]]), 'b3': array([[-1.73308753]])}\n"
     ]
    }
   ],
   "source": [
    "model.forePropagate(tx)\n",
    "\n",
    "print(model.W)\n",
    "print()\n",
    "print(model.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cost_calc(ty,loss_function = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.back_prop(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dW3': array([[0.2566086 , 0.29056385]]), 'dW2': array([[0.00253466, 0.00398755, 0.00198802],\n",
      "       [0.0056896 , 0.00895094, 0.00446254]]), 'dW1': array([[-7.43389179e-05, -8.79561635e-05, -9.23032101e-05],\n",
      "       [ 1.66912405e-05,  1.97508383e-05,  2.08054634e-05],\n",
      "       [ 1.71744874e-05,  2.03156533e-05,  2.13475901e-05]])}\n"
     ]
    }
   ],
   "source": [
    "print(model.dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.param_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009000000000000001 \t is the learning rate now\n",
      "epoch 0 : \t cost = 18.28069813149145\n",
      "learning rate / alpha \t0.009000000000000001\n",
      "\n",
      "0.008100000000000001 \t is the learning rate now\n",
      "0.007290000000000001 \t is the learning rate now\n",
      "0.006561000000000002 \t is the learning rate now\n",
      "0.005904900000000002 \t is the learning rate now\n",
      "0.005314410000000002 \t is the learning rate now\n",
      "0.004782969000000002 \t is the learning rate now\n",
      "0.004304672100000002 \t is the learning rate now\n",
      "0.003874204890000002 \t is the learning rate now\n",
      "0.003486784401000002 \t is the learning rate now\n",
      "0.003138105960900002 \t is the learning rate now\n",
      "epoch 100 : \t cost = 48.42346231480824\n",
      "learning rate / alpha \t0.003138105960900002\n",
      "\n",
      "0.0028242953648100018 \t is the learning rate now\n",
      "0.0025418658283290017 \t is the learning rate now\n",
      "0.0022876792454961017 \t is the learning rate now\n",
      "0.0020589113209464917 \t is the learning rate now\n",
      "0.0018530201888518425 \t is the learning rate now\n",
      "0.0016677181699666583 \t is the learning rate now\n",
      "0.0015009463529699924 \t is the learning rate now\n",
      "0.0013508517176729932 \t is the learning rate now\n",
      "0.001215766545905694 \t is the learning rate now\n",
      "0.0010941898913151245 \t is the learning rate now\n",
      "epoch 200 : \t cost = 62.30300217823695\n",
      "learning rate / alpha \t0.0010941898913151245\n",
      "\n",
      "0.0009847709021836122 \t is the learning rate now\n",
      "0.0008862938119652509 \t is the learning rate now\n",
      "0.0007976644307687258 \t is the learning rate now\n",
      "0.0007178979876918532 \t is the learning rate now\n",
      "0.0006461081889226679 \t is the learning rate now\n",
      "0.0005814973700304011 \t is the learning rate now\n",
      "0.0005233476330273611 \t is the learning rate now\n",
      "0.000471012869724625 \t is the learning rate now\n",
      "0.0004239115827521625 \t is the learning rate now\n",
      "0.00038152042447694626 \t is the learning rate now\n",
      "epoch 300 : \t cost = 67.4307292439626\n",
      "learning rate / alpha \t0.00038152042447694626\n",
      "\n",
      "0.00034336838202925164 \t is the learning rate now\n",
      "0.0003090315438263265 \t is the learning rate now\n",
      "0.00027812838944369386 \t is the learning rate now\n",
      "0.0002503155504993245 \t is the learning rate now\n",
      "0.00022528399544939206 \t is the learning rate now\n",
      "0.00020275559590445286 \t is the learning rate now\n",
      "0.00018248003631400757 \t is the learning rate now\n",
      "0.00016423203268260683 \t is the learning rate now\n",
      "0.00014780882941434616 \t is the learning rate now\n",
      "0.00013302794647291155 \t is the learning rate now\n",
      "epoch 400 : \t cost = 69.24912449388997\n",
      "learning rate / alpha \t0.00013302794647291155\n",
      "\n",
      "0.00011972515182562039 \t is the learning rate now\n",
      "0.00010775263664305835 \t is the learning rate now\n",
      "9.697737297875251e-05 \t is the learning rate now\n",
      "8.727963568087727e-05 \t is the learning rate now\n",
      "7.855167211278955e-05 \t is the learning rate now\n",
      "7.06965049015106e-05 \t is the learning rate now\n",
      "6.362685441135955e-05 \t is the learning rate now\n",
      "5.7264168970223595e-05 \t is the learning rate now\n",
      "5.153775207320124e-05 \t is the learning rate now\n",
      "epoch 500 : \t cost = 69.88669379383498\n",
      "learning rate / alpha \t5.153775207320124e-05\n",
      "\n",
      "epoch 600 : \t cost = 70.26260889826223\n",
      "learning rate / alpha \t5.153775207320124e-05\n",
      "\n",
      "epoch 700 : \t cost = 70.63914603019944\n",
      "learning rate / alpha \t5.153775207320124e-05\n",
      "\n",
      "epoch 800 : \t cost = 71.01630117194003\n",
      "learning rate / alpha \t5.153775207320124e-05\n",
      "\n",
      "epoch 900 : \t cost = 71.39407035306496\n",
      "learning rate / alpha \t5.153775207320124e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(tx,ty,verbose=100,lr_decay=True,learning_rate=0.01,epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.plot_cost_to_epoch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.009000000000000001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.008100000000000001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.007290000000000001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.006561000000000002, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.005904900000000002, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.005314410000000002, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.004782969000000002, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.004304672100000002, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.003874204890000002, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.003486784401000002, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.003138105960900002, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0028242953648100018, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0025418658283290017, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0022876792454961017, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0020589113209464917, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0018530201888518425, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0016677181699666583, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0015009463529699924, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0013508517176729932, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.001215766545905694, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0010941898913151245, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0009847709021836122, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0008862938119652509, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0007976644307687258, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0007178979876918532, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0006461081889226679, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0005814973700304011, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0005233476330273611, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.000471012869724625, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0004239115827521625, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00038152042447694626, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00034336838202925164, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0003090315438263265, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00027812838944369386, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0002503155504993245, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00022528399544939206, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00020275559590445286, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00018248003631400757, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00016423203268260683, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00014780882941434616, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00013302794647291155, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00011972515182562039, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.00010775263664305835, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 9.697737297875251e-05, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 8.727963568087727e-05, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 7.855167211278955e-05, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 7.06965049015106e-05, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 6.362685441135955e-05, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 5.7264168970223595e-05, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 5.153775207320124e-05, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ba53d94820>]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.lr_change)\n",
    "plt.plot(model.lr_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(324)\n",
    "testx = np.random.random((3,100))\n",
    "testy = np.random.random((1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = model.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "print(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mse_model_eval(testy,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 100)\n"
     ]
    }
   ],
   "source": [
    "print(tx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "obc = pd.read_csv('breast-cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "obc = obc.drop(['fractal_dimension_worst'],axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no features : 32 \n",
      " number of variaibles 569\n"
     ]
    }
   ],
   "source": [
    "print(f'no features : {obc.shape[1]} \\n number of variaibles {obc.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
